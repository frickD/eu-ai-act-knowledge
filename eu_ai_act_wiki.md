The **Artificial Intelligence Act** (**AI Act**) is a [European Union
regulation](Regulation_(European_Union) "wikilink") concerning
[artificial intelligence](artificial_intelligence "wikilink") (AI). It
establishes a common regulatory and [legal
framework](legal_framework "wikilink") for AI within the [European
Union](European_Union "wikilink") (EU).[^1] It comes into force on 1
August 2024, with provisions coming into operation gradually over the
following 6 to 36 months.[^2]

It covers all types of AI across a broad range of sectors, with
exceptions for AI systems used solely for military, national security,
research and non-professional purposes.[^3] As a piece of product
regulation, it does not confer rights on individuals, but regulates the
providers of AI systems and entities using AI in a professional
context.[^4]

The Act classifies non-exempt AI applications by their risk of causing
harm. There are four levels – unacceptable, high, limited, minimal –
plus an additional category for general-purpose AI. Applications with
unacceptable risks are banned. High-risk applications must comply with
security, [transparency](transparency_(behavior) "wikilink") and quality
obligations, and undergo [conformity
assessments](Conformity_assessment "wikilink"). Limited-risk
applications only have transparency obligations, while minimal-risk
applications are not regulated. For general-purpose AI, transparency
requirements are imposed, with additional evaluations for
high-capability models.[^5][^6]

The Act also creates a European Artificial Intelligence Board to promote
national cooperation and ensure compliance with the regulation.[^7] Like
the EU's [General Data Protection
Regulation](General_Data_Protection_Regulation "wikilink"), the Act can
apply [extraterritorially](Extraterritoriality "wikilink") to providers
from outside the EU if they have users within the EU.[^8]

Proposed by the [European Commission](European_Commission "wikilink") on
21 April 2021,[^9] it passed the [European
Parliament](European_Parliament "wikilink") on 13 March 2024,[^10] and
was unanimously approved by the [EU
Council](Council_of_the_European_Union "wikilink") on 21 May 2024.[^11]
The draft Act was revised to address the rise in popularity of
[generative artificial
intelligence](generative_artificial_intelligence "wikilink") systems,
such as [ChatGPT](ChatGPT "wikilink"), whose general-purpose
capabilities did not fit the main framework.[^12] More restrictive
regulations are planned for powerful generative AI systems with systemic
impact.[^13]

## Provisions

### Risk categories

There are different risk categories depending on the type of
application, with a specific category dedicated to general-purpose
generative AI:

-   Unacceptable risk – AI applications in this category are banned,
    except for [specific exemptions](#Exemptions "wikilink").[^14] When
    no exemption applies, this includes AI applications that [manipulate
    human behaviour](Manipulation_(psychology) "wikilink"), those that
    use real-time remote [biometric](Biometrics "wikilink")
    identification (such as [facial
    recognition](Facial_recognition_system "wikilink")) in public
    spaces, and those used for [social
    scoring](Social_Credit_System "wikilink") (ranking individuals based
    on their personal characteristics, socio-economic status or
    behaviour).[^15]
-   High-risk – AI applications that are expected to pose significant
    threats to health, safety, or the [fundamental
    rights](fundamental_rights "wikilink") of persons. Notably, AI
    systems used in health, education, recruitment, critical
    infrastructure management, law enforcement or justice. They are
    subject to quality, transparency, human oversight and safety
    obligations, and in some cases require a "Fundamental Rights Impact
    Assessment" before deployment.[^16] They must be evaluated both
    before they are placed on the market and throughout their life
    cycle. The list of high-risk applications can be expanded over time,
    without the need to modify the AI Act itself.[^17]
-   General-purpose AI – Added in 2023, this category includes in
    particular [foundation models](foundation_model "wikilink") like
    ChatGPT. They are subject to transparency requirements. High-impact
    general-purpose AI systems which could pose systemic risks (notably
    those trained using a computational capability exceeding
    10<sup>25</sup> [FLOPS](FLOPS "wikilink"))[^18] must also undergo a
    thorough evaluation process.[^19]
-   Limited risk – AI systems in this category have transparency
    obligations, ensuring users are informed that they are interacting
    with an AI system and allowing them to make informed choices. This
    category includes, for example, AI applications that make it
    possible to generate or manipulate images, sound, or videos (like
    [deepfakes](deepfake "wikilink")).[^20] In this category, free
    models that are [open source](open_source "wikilink") (*i.e.*, whose
    parameters are publicly available) are not regulated, with some
    exceptions.[^21][^22]
-   Minimal risk – This category includes, for example, AI systems used
    for video games or [spam filters](spam_filters "wikilink"). Most AI
    applications are expected to fall into this category.[^23] These
    systems are not regulated, and Member States cannot impose
    additional regulations due to [maximum
    harmonisation](maximum_harmonisation "wikilink") rules. Existing
    national laws regarding the design or use of such systems are
    overridden. However, a voluntary code of conduct is suggested.[^24]

### Exemptions

Articles 2.3 and 2.6 exempt AI systems used for
[military](Artificial_intelligence#Military "wikilink") or [national
security](Artificial_intelligence_in_government "wikilink") purposes or
pure scientific research and development from the AI Act.[^25]

Article 5.2 bans algorithmic video surveillance only if it is conducted
in real time. Exceptions allowing real-time algorithmic video
surveillance include policing aims including "a real and present or real
and foreseeable threat of terrorist attack".[^26]

Recital 31 of the act states that it aims to prohibit "AI systems
providing social scoring of natural persons by public or private
actors", but allows for "lawful evaluation practices of natural persons
that are carried out for a specific purpose in accordance with Union and
national law."[^27] [La Quadrature du
Net](La_Quadrature_du_Net "wikilink") interprets this exemption as
permitting sector-specific social scoring systems,[^28] such as the
suspicion score used by the French family payments agency .[^29][^30]

### Governance

The AI Act establishes various new bodies in Article 64 and the
following articles. These bodies are tasked with implementing and
enforcing the Act. The approach combines EU-level coordination with
national implementation, involving both public authorities and private
sector participation.

The following new bodies will be established:[^31][^32]

1.  AI Office: attached to the European Commission, this authority will
    coordinate the implementation of the AI Act in all Member States and
    oversee the compliance of general-purpose AI providers.
2.  European Artificial Intelligence Board: composed of one
    representative from each Member State, the Board will advise and
    assist the Commission and Member States to facilitate the consistent
    and effective application of the AI Act. Its tasks include gathering
    and sharing technical and regulatory expertise, providing
    recommendations, written opinions, and other advice.
3.  Advisory Forum: established to advise and provide technical
    expertise to the Board and the Commission, this forum will represent
    a balanced selection of stakeholders, including industry, start-ups,
    small and medium-sized enterprises, civil society, and academia,
    ensuring that a broad spectrum of opinions is represented during the
    implementation and application process.
4.  Scientific Panel of Independent Experts: this panel will provide
    technical advice and input to the AI Office and national
    authorities, enforce rules for general-purpose AI models (notably by
    launching qualified alerts of possible risks to the AI Office), and
    ensure that the rules and implementations of the AI Act correspond
    to the latest scientific findings.

While the establishment of new bodies is planned at the EU level, Member
States will have to designate "national competent authorities".[^33]
These authorities will be responsible for ensuring the application and
implementation of the AI Act, and for conducting "market
surveillance".[^34] They will verify that AI systems comply with the
regulations, notably by checking the proper performance of conformity
assessments and by appointing third-parties to carry out external
conformity assessments.

### Enforcement

The Act regulates the entry to the [EU internal
market](EU_internal_market "wikilink") using the New Legislative
Framework. It contains essential requirements that all AI systems must
meet to access the EU market. These essential requirements are passed on
to European Standardisation Organisations, which develop technical
standards that further detail these requirements.[^35]

The Act mandates that member states establish their own notifying
bodies. Conformity assessments are conducted to verify whether AI
systems comply with the standards set out in the AI Act.[^36] This
assessment can be done in two ways: either through self-assessment,
where the AI system provider checks conformity, or through third-party
conformity assessment, where the notifying body conducts the
assessment.[^37] Notifying bodies also have the authority to carry out
audits to ensure proper conformity assessments.[^38]

Criticism has arisen regarding the fact that many high-risk AI systems
do not require third-party conformity assessments.[^39][^40][^41] Some
commentators argue that independent third-party assessments are
necessary for high-risk AI systems to ensure safety before deployment.
Legal scholars have suggested that AI systems capable of generating
deepfakes for political misinformation or creating non-consensual
intimate imagery should be classified as high-risk and subjected to
stricter regulation.[^42]

## Legislative procedure

In February 2020, the [European
Commission](European_Commission "wikilink") published "White Paper on
Artificial Intelligence – A European approach to excellence and
trust".[^43] In October 2020, debates between EU leaders took place in
the [European Council](European_Council "wikilink"). On 21 April 2021,
the AI Act was officially proposed by the Commission. On 6 December
2022, the European Council adopted the general orientation, allowing
negotiations to begin with the [European
Parliament](European_Parliament "wikilink"). On 9 December 2023, after
three days of "marathon" talks, the [EU
Council](Council_of_the_European_Union "wikilink") and Parliament
concluded an agreement.[^44]

The law was passed in the European Parliament on 13 March 2024, by a
vote of 523 for, 46 against, and 49 abstaining.[^45] It was approved by
the EU Council on 21 May 2024.[^46] It will come into force on 1 August
2024, 20 days after being published in the *[Official
Journal](Official_Journal_of_the_European_Union "wikilink")* on 12 July
2024.[^47][^48] After coming into force, there will be a delay before it
becomes applicable, which depends on the type of application. This delay
is 6 months for bans on "unacceptable risk" AI systems, 9 months for
codes of practice, 12 months for general-purpose AI systems, 36 months
for some obligations related to "high-risk" AI systems, and 24 months
for everything else.[^49][^50]

## Reactions

Experts have argued that though the jurisdiction of the law is European,
it could have far-ranging implications for international companies that
plan to expand to Europe.[^51] [Anu Bradford](Anu_Bradford "wikilink")
at [Columbia](Columbia_University "wikilink") has argued that the law
provides significant momentum to the world-wide movement to regulate AI
technologies.[^52]

[Amnesty International](Amnesty_International "wikilink") criticized the
AI Act for not completely banning real-time [facial
recognition](Facial_recognition_system "wikilink"), which they said
could damage "human rights, civil space and rule of law" in the European
Union. It also criticized the absence of ban on *exporting* AI
technologies that can harm human rights.[^53]

Some tech watchdogs have argued that there were major loopholes in the
law that would allow large tech monopolies to entrench their advantage
in AI, or to lobby to weaken rules.[^54][^55] Some startups welcomed the
clarification the act provides, while others argued the additional
regulation would make European startups uncompetitive compared to
American and Chinese startups.[^56] [La Quadrature du
Net](La_Quadrature_du_Net "wikilink") (LQDN) described the AI Act as
"tailor-made for the tech industry, European police forces as well as
other large bureaucracies eager to automate social control". LQDN
described the role of self-regulation and exemptions in the act to
render it "largely incapable of standing in the way of the social,
political and environmental damage linked to the proliferation of
AI".[^57]

## See also

-   [Algorithmic bias](Algorithmic_bias "wikilink")
-   [Ethics of artificial
    intelligence](Ethics_of_artificial_intelligence "wikilink")
-   [Regulation of algorithms](Regulation_of_algorithms "wikilink")
-   [Regulation of artificial intelligence in the European
    Union](Regulation_of_artificial_intelligence_in_the_European_Union "wikilink")
-   [Existential risk from artificial general
    intelligence](Existential_risk_from_artificial_general_intelligence "wikilink")

## Notes

## References

[Category:Policies of the European
Union](Category:Policies_of_the_European_Union "wikilink")
[Category:European Digital
Strategy](Category:European_Digital_Strategy "wikilink") [Category:2021
in law](Category:2021_in_law "wikilink") [Category:2021 in the European
Union](Category:2021_in_the_European_Union "wikilink") [Category:2024 in
law](Category:2024_in_law "wikilink") [Category:2024 in
politics](Category:2024_in_politics "wikilink") [Category:Data
laws](Category:Data_laws "wikilink") [Category:European Union
regulations](Category:European_Union_regulations "wikilink")
[Category:Regulation of
robots](Category:Regulation_of_robots "wikilink") [Category:Regulation
of artificial
intelligence](Category:Regulation_of_artificial_intelligence "wikilink")